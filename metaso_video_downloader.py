#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Metasoè§†é¢‘ä¸‹è½½å™¨
ä¸“é—¨ç”¨äºä¸‹è½½Metasoç½‘ç«™ä¸Šç”±PPTè½¬æ¢ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶
"""

import sys
import os
import re
import json
import time
import requests
from urllib.parse import urlparse, parse_qs, unquote
from bs4 import BeautifulSoup
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

class MetasoVideoDownloader:
    """Metasoè§†é¢‘ä¸‹è½½å™¨"""
    
    def __init__(self, download_dir="downloads", uid=None, sid=None):
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(exist_ok=True)
        
        self.session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://metaso.cn/',
            'Origin': 'https://metaso.cn'
        }
        
        # å¦‚æœæä¾›äº†è®¤è¯ä¿¡æ¯ï¼Œæ·»åŠ Authorizationå¤´
        if uid and sid:
            token = f"{uid}-{sid}"
            headers['Authorization'] = f'Bearer {token}'
            print(f"ğŸ” å·²è®¾ç½®è®¤è¯ä¿¡æ¯: {uid[:10]}...")
        
        self.session.headers.update(headers)
    
    def parse_url_info(self, url):
        """è§£æURLä¸­çš„æ–‡ä»¶ä¿¡æ¯"""
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        
        info = {
            'file_id': query_params.get('_id', [''])[0],
            'chapter_id': query_params.get('chapterId', [''])[0],
            'total_pages': query_params.get('totalPage', [''])[0],
            'file_type': query_params.get('type', [''])[0],
            'title': unquote(query_params.get('title', [''])[0], encoding='utf-8'),
            'scene': unquote(query_params.get('scene', [''])[0], encoding='utf-8'),
            'voice_language': query_params.get('voiceLanguage', [''])[0],
            'voice_speed': query_params.get('voiceSpeed', [''])[0],
            'tts_timbre': query_params.get('ttsTimbre', [''])[0],
            'show_captions': query_params.get('showCaptions', [''])[0]
        }
        
        return info
    
    def get_page_content(self, url):
        """è·å–é¡µé¢å†…å®¹"""
        try:
            print(f"ğŸ“„ æ­£åœ¨è·å–é¡µé¢å†…å®¹: {url}")
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return soup, response.text
            
        except Exception as e:
            print(f"âŒ è·å–é¡µé¢å†…å®¹å¤±è´¥: {e}")
            return None, None
    
    def find_video_apis(self, page_content):
        """åœ¨é¡µé¢å†…å®¹ä¸­æŸ¥æ‰¾è§†é¢‘ç›¸å…³çš„APIç«¯ç‚¹"""
        video_apis = []
        
        # æŸ¥æ‰¾å¯èƒ½çš„è§†é¢‘APIæ¨¡å¼ - ä½¿ç”¨ç®€åŒ–çš„æ­£åˆ™è¡¨è¾¾å¼
        patterns = [
            r'/api/[^/\s]*/video[^\s"]*',  # è§†é¢‘API
            r'/api/[^/\s]*/stream[^\s"]*',  # æµåª’ä½“API
            r'/api/[^/\s]*/media[^\s"]*',   # åª’ä½“API
            r'/api/[^/\s]*/play[^\s"]*',    # æ’­æ”¾API
            r'/api/[^/\s]*/export[^\s"]*',  # å¯¼å‡ºAPI
            r'/api/[^/\s]*/generate[^\s"]*', # ç”ŸæˆAPI
            r'videoUrl.*?(["\'])([^"\']*)\1',     # videoUrlå˜é‡
            r'streamUrl.*?(["\'])([^"\']*)\1',    # streamUrlå˜é‡
            r'downloadUrl.*?(["\'])([^"\']*)\1',  # downloadUrlå˜é‡
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, page_content, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    # å¯¹äºå¸¦åˆ†ç»„çš„åŒ¹é…ï¼Œå–æœ€åä¸€ä¸ªåˆ†ç»„
                    match = match[-1]
                
                if match and not match.startswith('http'):
                    # è¡¥å…¨URL
                    full_url = f"https://metaso.cn{match}" if match.startswith('/') else f"https://metaso.cn/{match}"
                    video_apis.append(full_url)
                elif match and match.startswith('http'):
                    video_apis.append(match)
        
        # å»é‡
        return list(set(video_apis))
    
    def find_video_elements(self, soup):
        """æŸ¥æ‰¾é¡µé¢ä¸­çš„è§†é¢‘å…ƒç´ """
        video_elements = []
        
        # æŸ¥æ‰¾videoæ ‡ç­¾
        videos = soup.find_all('video')
        for video in videos:
            src = video.get('src')
            if src:
                video_elements.append({
                    'type': 'video_tag',
                    'src': src,
                    'attributes': dict(video.attrs)
                })
            
            # æŸ¥æ‰¾sourceæ ‡ç­¾
            sources = video.find_all('source')
            for source in sources:
                src = source.get('src')
                if src:
                    video_elements.append({
                        'type': 'source_tag',
                        'src': src,
                        'attributes': dict(source.attrs)
                    })
        
        # æŸ¥æ‰¾iframe
        iframes = soup.find_all('iframe')
        for iframe in iframes:
            src = iframe.get('src')
            if src and ('video' in src.lower() or 'stream' in src.lower() or 'play' in src.lower()):
                video_elements.append({
                    'type': 'iframe',
                    'src': src,
                    'attributes': dict(iframe.attrs)
                })
        
        return video_elements
    
    def try_video_api_endpoints(self, file_info):
        """å°è¯•å„ç§å¯èƒ½çš„è§†é¢‘APIç«¯ç‚¹"""
        file_id = file_info['file_id']
        chapter_id = file_info['chapter_id']
        
        # å¯èƒ½çš„è§†é¢‘APIç«¯ç‚¹
        api_endpoints = [
            f"/api/file/{file_id}/video",
            f"/api/file/{file_id}/stream",
            f"/api/file/{file_id}/media",
            f"/api/file/{file_id}/play",
            f"/api/file/{file_id}/export/video",
            f"/api/file/{file_id}/generate/video",
            f"/api/chapter/{chapter_id}/video",
            f"/api/chapter/{chapter_id}/stream",
            f"/api/chapter/{chapter_id}/export",
            f"/api/video/{file_id}",
            f"/api/media/{file_id}",
            f"/api/stream/{file_id}",
            f"/api/ppt/{file_id}/video",
            f"/api/courseware/{file_id}/video",
        ]
        
        successful_endpoints = []
        
        for endpoint in api_endpoints:
            full_url = f"https://metaso.cn{endpoint}"
            try:
                print(f"ğŸ” å°è¯•APIç«¯ç‚¹: {endpoint}")
                response = self.session.get(full_url, timeout=10)
                
                print(f"   çŠ¶æ€ç : {response.status_code}")
                print(f"   Content-Type: {response.headers.get('content-type', 'unknown')}")
                
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '')
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶
                    if content_type.startswith('video/'):
                        print(f"âœ… æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {endpoint}")
                        successful_endpoints.append({
                            'url': full_url,
                            'content_type': content_type,
                            'size': response.headers.get('content-length', 'unknown')
                        })
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯JSONå“åº”
                    elif content_type.startswith('application/json'):
                        try:
                            data = response.json()
                            print(f"   JSONå“åº”: {json.dumps(data, ensure_ascii=False, indent=2)[:200]}...")
                            
                            # æŸ¥æ‰¾JSONä¸­çš„è§†é¢‘URL
                            video_url = self.extract_video_url_from_json(data)
                            if video_url:
                                print(f"âœ… åœ¨JSONä¸­æ‰¾åˆ°è§†é¢‘URL: {video_url}")
                                successful_endpoints.append({
                                    'url': video_url,
                                    'source': 'json_response',
                                    'api_endpoint': full_url
                                })
                        except:
                            pass
                    
                    # æ£€æŸ¥å“åº”å†…å®¹é•¿åº¦
                    elif len(response.content) > 1000:  # å¯èƒ½æ˜¯è§†é¢‘æ–‡ä»¶
                        print(f"âš ï¸ å¤§æ–‡ä»¶å“åº”ï¼Œå¯èƒ½æ˜¯è§†é¢‘: {len(response.content)} bytes")
                        successful_endpoints.append({
                            'url': full_url,
                            'content_type': content_type,
                            'size': len(response.content)
                        })
                
                elif response.status_code == 401:
                    print(f"   éœ€è¦è®¤è¯")
                elif response.status_code == 403:
                    print(f"   æƒé™ä¸è¶³")
                elif response.status_code == 404:
                    print(f"   ç«¯ç‚¹ä¸å­˜åœ¨")
                else:
                    print(f"   å…¶ä»–é”™è¯¯: {response.status_code}")
                    
            except Exception as e:
                print(f"   è¯·æ±‚å¤±è´¥: {e}")
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        return successful_endpoints
    
    def extract_video_url_from_json(self, data):
        """ä»JSONæ•°æ®ä¸­æå–è§†é¢‘URL"""
        if isinstance(data, dict):
            for key, value in data.items():
                if key.lower() in ['video_url', 'videourl', 'stream_url', 'streamurl', 'media_url', 'mediaurl', 'download_url', 'downloadurl']:
                    if isinstance(value, str) and (value.startswith('http') or value.startswith('/')):
                        return value
                elif isinstance(value, (dict, list)):
                    result = self.extract_video_url_from_json(value)
                    if result:
                        return result
        elif isinstance(data, list):
            for item in data:
                result = self.extract_video_url_from_json(item)
                if result:
                    return result
        return None
    
    def download_video(self, video_url, filename):
        """ä¸‹è½½è§†é¢‘æ–‡ä»¶"""
        try:
            print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘: {filename}")
            print(f"   URL: {video_url}")
            
            response = self.session.get(video_url, stream=True, timeout=60)
            response.raise_for_status()
            
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('content-type', '')
            print(f"   Content-Type: {content_type}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            print(f"   æ–‡ä»¶å¤§å°: {total_size} bytes ({total_size / 1024 / 1024:.2f} MB)")
            
            if total_size < 1000:  # æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ˜¯é”™è¯¯ä¿¡æ¯
                content = response.content.decode('utf-8', errors='ignore')
                print(f"   å“åº”å†…å®¹: {content}")
                return False
            
            filepath = self.download_dir / filename
            downloaded_size = 0
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            print(f"\r   ä¸‹è½½è¿›åº¦: {progress:.1f}%", end='', flush=True)
            
            print(f"\nâœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {filepath}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_from_url(self, url):
        """ä»Metaso URLä¸‹è½½è§†é¢‘"""
        print("=" * 80)
        print("ğŸ¬ Metasoè§†é¢‘ä¸‹è½½å™¨")
        print("=" * 80)
        
        # è§£æURLä¿¡æ¯
        file_info = self.parse_url_info(url)
        print(f"\nğŸ“‹ æ–‡ä»¶ä¿¡æ¯:")
        for key, value in file_info.items():
            if value:
                print(f"   {key}: {value}")
        
        if not file_info['file_id']:
            print("âŒ æ— æ³•ä»URLä¸­æå–æ–‡ä»¶ID")
            return False
        
        # è·å–é¡µé¢å†…å®¹
        soup, page_content = self.get_page_content(url)
        if not soup:
            return False
        
        # æŸ¥æ‰¾é¡µé¢ä¸­çš„è§†é¢‘API
        print(f"\nğŸ” æŸ¥æ‰¾è§†é¢‘APIç«¯ç‚¹...")
        video_apis = self.find_video_apis(page_content)
        if video_apis:
            print(f"   æ‰¾åˆ° {len(video_apis)} ä¸ªå¯èƒ½çš„è§†é¢‘API:")
            for api in video_apis:
                print(f"   - {api}")
        
        # æŸ¥æ‰¾è§†é¢‘å…ƒç´ 
        print(f"\nğŸ¥ æŸ¥æ‰¾è§†é¢‘å…ƒç´ ...")
        video_elements = self.find_video_elements(soup)
        if video_elements:
            print(f"   æ‰¾åˆ° {len(video_elements)} ä¸ªè§†é¢‘å…ƒç´ :")
            for element in video_elements:
                print(f"   - {element['type']}: {element['src']}")
        
        # å°è¯•å„ç§APIç«¯ç‚¹
        print(f"\nğŸš€ å°è¯•è§†é¢‘APIç«¯ç‚¹...")
        successful_endpoints = self.try_video_api_endpoints(file_info)
        
        if successful_endpoints:
            print(f"\nâœ… æ‰¾åˆ° {len(successful_endpoints)} ä¸ªå¯ç”¨çš„è§†é¢‘æº:")
            for i, endpoint in enumerate(successful_endpoints):
                print(f"   {i+1}. {endpoint['url']}")
                if 'content_type' in endpoint:
                    print(f"      ç±»å‹: {endpoint['content_type']}")
                if 'size' in endpoint:
                    print(f"      å¤§å°: {endpoint['size']}")
                
                # å°è¯•ä¸‹è½½ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„è§†é¢‘
                if i == 0:
                    filename = f"{file_info['title']}.mp4" if file_info['title'] else f"video_{file_info['file_id']}.mp4"
                    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
                    
                    success = self.download_video(endpoint['url'], filename)
                    if success:
                        return True
        
        print("\nâŒ æœªæ‰¾åˆ°å¯ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶")
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. ç¡®è®¤è§†é¢‘å·²ç»ç”Ÿæˆå®Œæˆ")
        print("   2. æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•è®¤è¯")
        print("   3. å°è¯•æ‰‹åŠ¨ç™»å½•åå†è¿è¡Œè„šæœ¬")
        
        return False

def main():
    import sys
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    uid = None
    sid = None
    
    for arg in sys.argv[1:]:
        if arg.startswith('--uid='):
            uid = arg.split('=', 1)[1]
        elif arg.startswith('--sid='):
            sid = arg.split('=', 1)[1]
    
    # ç”¨æˆ·æä¾›çš„URL
    target_url = "https://metaso.cn/bookshelf?displayUrl=%2Fapi%2Ffile%2F8651522172447916032%2Fpreview&url=%2Fapi%2Ffile%2F8651522172447916032%2Fpreview&page=1&totalPage=44&file_path=&_id=8651522172447916032&title=%E3%80%90%E8%AF%BE%E4%BB%B6%E3%80%91%E7%AC%AC1%E7%AB%A0_%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0.pptx&snippet=undefined&sessionId=null&tag=%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%88%B0%E4%B9%A6%E6%9E%B6%E4%B8%93%E7%94%A8%E4%B8%93%E9%A2%98654ce6f986a91de24c79b52f&author=&publishDate=undefined&showFront=false&downloadUrl=%2Fapi%2Ffile%2F8651522172447916032%2Fdownload&previewUrl=%2Fapi%2Ffile%2F8651522172447916032%2Fpreview&internalFile=true&topicId=undefined&type=pptx&readMode=false&chapterId=8651523279591608320&level=3&scene=%E9%BB%98%E8%AE%A4&voiceLanguage=cn&pptLanguage=cn&ttsTimbre=uk_woman16&voiceSpeed=100&showCaptions=true"
    
    print("="*80)
    print("ğŸ¬ Metasoè§†é¢‘ä¸‹è½½å™¨ (å¸¦è®¤è¯æ”¯æŒ)")
    print("="*80)
    
    if uid and sid:
        print(f"ğŸ” ä½¿ç”¨è®¤è¯ä¿¡æ¯: UID={uid[:10]}..., SID={sid[:10]}...")
    else:
        print("âš ï¸ æœªæä¾›è®¤è¯ä¿¡æ¯ï¼Œå°†å°è¯•æ— è®¤è¯ä¸‹è½½")
        print("ğŸ’¡ å¦‚éœ€è®¤è¯ï¼Œè¯·ä½¿ç”¨: python metaso_video_downloader.py --uid=ä½ çš„uid --sid=ä½ çš„sid")
    
    downloader = MetasoVideoDownloader(uid=uid, sid=sid)
    downloader.download_from_url(target_url)

if __name__ == "__main__":
    main()